{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- __name : kitti_train\n",
      "- name : <type 'function'>\n",
      "- __name : kitti_val\n",
      "- name : <type 'function'>\n",
      "- __name : kitti_trainval\n",
      "- name : <type 'function'>\n",
      "- __name : kitti_test\n",
      "- name : <type 'function'>\n"
     ]
    }
   ],
   "source": [
    "import _init_paths\n",
    "from fast_rcnn.train_mv import get_training_roidb, train_net\n",
    "from fast_rcnn.config import cfg,cfg_from_file, cfg_from_list, get_output_dir\n",
    "from datasets.factory import get_imdb\n",
    "from networks.factory import get_network\n",
    "import argparse\n",
    "import pprint\n",
    "import numpy as np\n",
    "import sys\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python ./train_net.py --device gpu --device_id 0 --weights /workspace/MV3D_TF/data/pretrain_model/VGG_imagenet.npy --iters 1 --cfg /workspace/MV3D_TF/experiments/cfgs/faster_rcnn_end2end.yml --network MV3D_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. get_imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- get_imdb(name) : kitti_train\n",
      "<bound method kitti_mv3d.default_roidb of <datasets.kitti_mv3d.kitti_mv3d object at 0x7f72ad76df90>>\n",
      "-$$$$ PATH : ../lib/datasets/../../data/KITTI---train\n",
      "image sets length:  4682\n",
      "- image_set_file : ../lib/datasets/../../data/KITTI/ImageSets/train.txt\n"
     ]
    }
   ],
   "source": [
    "imdb_name = 'kitti_train'\n",
    "imdb = get_imdb(imdb_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_imdb(name):\n",
    "    \"\"\"Get an imdb (image database) by name.\"\"\"\n",
    "    print(\"- get_imdb(name) : {}\".format(name))\n",
    "    if not __sets.has_key(name):\n",
    "        raise KeyError('Unknown dataset: {}'.format(name))\n",
    "\n",
    "    return __sets[name]()\n",
    "```\n",
    "## 1.1 sets[name]처리 부분\n",
    "```\n",
    "for split in ['train', 'val', 'trainval', 'test']:\n",
    "    name = 'kitti_{}'.format(split)\n",
    "    print(\"- __name : {}\".format(name))\n",
    "    __sets[name] = (lambda split=split:\n",
    "            datasets.kitti_mv3d.kitti_mv3d(split))\n",
    "```\n",
    "\n",
    "## 1.2 datasets.kitti_mv3d.kitti_mv3d(split) 가 실행 : 경로 및 확장자 설정\n",
    "\n",
    "```python\n",
    "class kitti_mv3d(datasets.imdb):\n",
    "    def __init__(self, image_set, kitti_path=None):\n",
    "        datasets.imdb.__init__(self, image_set)\n",
    "        self._image_set = image_set\n",
    "        self._kitti_path = self._get_default_path() if kitti_path is None \\\n",
    "                            else kitti_path\n",
    "\n",
    "        self._data_path = os.path.join(self._kitti_path, 'object')\n",
    "        self._classes = ('__background__', 'Car')#, 'Pedestrian', 'Cyclist')\n",
    "        self._class_to_ind = dict(zip(self.classes, xrange(self.num_classes)))\n",
    "        self._image_ext = '.png'\n",
    "        self._lidar_ext = '.npy'\n",
    "        self._subset = 'car'\n",
    "        self._image_index = self._load_image_set_index() #IamgeSets/train.txt파일, 4681개의 숫자 list\n",
    "        self._roidb_handler = self.gt_roidb\n",
    "\n",
    "        self.config = {'top_k': 100000}\n",
    "        assert os.path.exists(self._kitti_path), \\\n",
    "                'KITTI path does not exist: {}'.format(self._kitti_path)\n",
    "        assert os.path.exists(self._data_path), \\\n",
    "                'Path does not exist: {}'.format(self._data_path)\n",
    "```\n",
    "\n",
    "## 1.3 datasets.imdb.__init__(self, image_set)\n",
    "```\n",
    "    def __init__(self, name):\n",
    "        self._name = name\n",
    "        self._num_classes = 0\n",
    "        self._classes = []\n",
    "        self._image_index = []\n",
    "        self._obj_proposer = 'selective_search'\n",
    "        self._roidb = None\n",
    "        print self.default_roidb\n",
    "        self._roidb_handler = self.default_roidb\n",
    "        # Use this dict for storing dataset specific config options\n",
    "        self.config = {}\n",
    " ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset `train` for training\n"
     ]
    }
   ],
   "source": [
    "print 'Loaded dataset `{:s}` for training'.format(imdb.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-imdb.classes:('__background__', 'Car')\n",
      "-imdb._num_classes:0\n",
      "-imdb._obj_proposer:selective_search\n",
      "-type(imdb._roidb):<type 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "print(\"-imdb.classes:{}\".format(imdb.classes))\n",
    "print(\"-imdb._num_classes:{}\".format(imdb._num_classes))\n",
    "#print(\"-imdb._classes:{}\".format(imdb._classes))\n",
    "#print(\"-imdb._image_index:{}\".format(imdb._image_index))\n",
    "print(\"-imdb._obj_proposer:{}\".format(imdb._obj_proposer))\n",
    "print(\"-type(imdb._roidb):{}\".format(type(imdb._roidb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. roidb = get_training_roidb(imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- get_training_roidb(imdb) : <datasets.kitti_mv3d.kitti_mv3d object at 0x7f72ad76df90>\n",
      "Preparing training data...\n",
      "call : rdl_roidb.prepare_roidb(imdb)\n",
      "train gt roidb loaded from /workspace/MV3D_TF/data/cache/train_gt_roidb.pkl\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roidb = get_training_roidb(imdb)\n",
    "type(roidb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def get_training_roidb(imdb):\n",
    "    \"\"\"Returns a roidb (Region of Interest database) for use in training.\"\"\"\n",
    "    print(\"- get_training_roidb(imdb) : {}\".format(imdb))\n",
    "    if cfg.TRAIN.USE_FLIPPED:\n",
    "        print 'Appending horizontally-flipped training examples...'\n",
    "        imdb.append_flipped_images()\n",
    "        print 'done'\n",
    "\n",
    "    print 'Preparing training data...'\n",
    "    if cfg.TRAIN.HAS_RPN:\n",
    "        if cfg.IS_MULTISCALE:\n",
    "            gdl_roidb.prepare_roidb(imdb)\n",
    "        else:\n",
    "            rdl_roidb.prepare_roidb(imdb)\n",
    "    else:\n",
    "        rdl_roidb.prepare_roidb(imdb)  ## called \n",
    "    print 'done'\n",
    "\n",
    "    return imdb.roidb\n",
    "```\n",
    "\n",
    "## 2.1  rdl_roidb.prepare_roidb(imdb)\n",
    "\n",
    "```python\n",
    "# import roi_data_layer.roidb as rdl_roidb\n",
    "\n",
    "def prepare_roidb(imdb):\n",
    "    \"\"\"Enrich the imdb's roidb by adding some derived quantities that\n",
    "    are useful for training. This function precomputes the maximum\n",
    "    overlap, taken over ground-truth boxes, between each ROI and\n",
    "    each ground-truth box. The class with maximum overlap is also\n",
    "    recorded.\n",
    "    \"\"\"\n",
    "    roidb = imdb.roidb\n",
    "\n",
    "    for i in xrange(len(imdb.image_index)):\n",
    "\n",
    "        if roidb[i]['boxes_corners'] == []:\n",
    "            print 'boxes_corners not correct', imdb.image_path_at(i)\n",
    "            continue\n",
    "        roidb[i]['image_path'] = imdb.image_path_at(i)\n",
    "        roidb[i]['lidar_bv_path'] = imdb.lidar_path_at(i)\n",
    "        roidb[i]['calib'] = imdb.calib_at(i)\n",
    "\n",
    "        # need gt_overlaps as a dense array for argmax\n",
    "        gt_overlaps = roidb[i]['gt_overlaps'].toarray()\n",
    "        max_overlaps = gt_overlaps.max(axis=1)\n",
    "        max_classes = gt_overlaps.argmax(axis=1)\n",
    "\n",
    "        roidb[i]['max_classes'] = max_classes\n",
    "        roidb[i]['max_overlaps'] = max_overlaps\n",
    "        zero_inds = np.where(max_overlaps == 0)[0]\n",
    "        nonzero_inds = np.where(max_overlaps > 0)[0]\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be saved to `/workspace/MV3D_TF/output/default/train`\n"
     ]
    }
   ],
   "source": [
    "output_dir = get_output_dir(imdb, None)\n",
    "print 'Output will be saved to `{:s}`'.format(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3.     network = get_network(args.network_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder:0\", shape=(?, ?, ?, 9), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(?, ?, ?, 3), dtype=float32)\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_cls_score/rpn_cls_score:0\", shape=(?, ?, ?, 8), dtype=float32)\n",
      "Tensor(\"Placeholder_4:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"Placeholder_5:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"rpn_conv/3x3/rpn_conv/3x3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"rpn_cls_score/rpn_cls_score:0\", shape=(?, ?, ?, 8), dtype=float32)\n",
      "Tensor(\"rpn_cls_prob:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "Tensor(\"Reshape_2:0\", shape=(?, ?, ?, 8), dtype=float32)\n",
      "Tensor(\"rpn_bbox_pred/rpn_bbox_pred:0\", shape=(?, ?, ?, 24), dtype=float32)\n",
      "Tensor(\"Placeholder_2:0\", shape=(?, 3), dtype=float32)\n",
      "Tensor(\"Placeholder_7:0\", shape=(?, 12), dtype=float32)\n",
      "(<tf.Tensor 'rpn_rois/rpn_rois_bv:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'rpn_rois/rpn_rois_img:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'rpn_rois/rpn_rois_3d:0' shape=(?, 7) dtype=float32>, <tf.Tensor 'rpn_rois/rpn_rois_3d:0' shape=(?, 7) dtype=float32>)\n",
      "Tensor(\"Placeholder_4:0\", shape=(?, 5), dtype=float32)\n",
      "Tensor(\"Placeholder_5:0\", shape=(?, 7), dtype=float32)\n",
      "Tensor(\"Placeholder_6:0\", shape=(?, 25), dtype=float32)\n",
      "Tensor(\"Placeholder_7:0\", shape=(?, 12), dtype=float32)\n",
      "(<tf.Tensor 'roi_data_3d/rois_bv:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'roi_data_3d/rois_img:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'roi_data_3d/PyFunc:2' shape=<unknown> dtype=int32>, <tf.Tensor 'roi_data_3d/PyFunc:3' shape=<unknown> dtype=float32>, <tf.Tensor 'roi_data_3d/rois_3d:0' shape=(?, 7) dtype=float32>)\n",
      "(<tf.Tensor 'roi_data_3d/rois_bv:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'roi_data_3d/rois_img:0' shape=(?, 5) dtype=float32>, <tf.Tensor 'roi_data_3d/PyFunc:2' shape=<unknown> dtype=int32>, <tf.Tensor 'roi_data_3d/PyFunc:3' shape=<unknown> dtype=float32>, <tf.Tensor 'roi_data_3d/rois_3d:0' shape=(?, 7) dtype=float32>)\n",
      "Tensor(\"conv5_3/conv5_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"roi_data_3d/rois_bv:0\", shape=(?, 5), dtype=float32)\n",
      "[<tf.Tensor 'conv5_3/conv5_3:0' shape=(?, ?, ?, 512) dtype=float32>, <tf.Tensor 'roi_data_3d/rois_bv:0' shape=(?, 5) dtype=float32>]\n",
      "Tensor(\"conv5_3_2/conv5_3_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "Tensor(\"roi_data_3d/rois_img:0\", shape=(?, 5), dtype=float32)\n",
      "[<tf.Tensor 'conv5_3_2/conv5_3_2:0' shape=(?, ?, ?, 512) dtype=float32>, <tf.Tensor 'roi_data_3d/rois_img:0' shape=(?, 5) dtype=float32>]\n",
      "Tensor(\"drop7/mul:0\", shape=(?, 2048), dtype=float32)\n",
      "Tensor(\"drop7_2/mul:0\", shape=(?, 2048), dtype=float32)\n",
      "Tensor(\"drop7_1/mul:0\", shape=(?, 4096), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "network_name = \"MV3D_train\"\n",
    "network = get_network(network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def get_network(name):\n",
    "    \"\"\"Get a network by name.\"\"\"\n",
    "    #if not __sets.has_key(name):\n",
    "    #    raise KeyError('Unknown dataset: {}'.format(name))\n",
    "    #return __sets[name]\n",
    "    if name.split('_')[1] == 'test':\n",
    "       return MV3D_test()\n",
    "    elif name.split('_')[1] == 'train':\n",
    "       return MV3D_train()\n",
    "    else:\n",
    "       raise KeyError('Unknown dataset: {}'.format(name))\n",
    "```\n",
    "## 3.1  MV3D_train()\n",
    "```python\n",
    "class MV3D_train(Network):\n",
    "    def __init__(self, trainable=True):\n",
    "        self.inputs = []\n",
    "        self.lidar_bv_data = tf.placeholder(tf.float32, shape=[None, None, None, 9])\n",
    "        self.image_data = tf.placeholder(tf.float32, shape=[None, None, None, 3])\n",
    "        self.im_info = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "        self.gt_boxes = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "        self.gt_boxes_bv = tf.placeholder(tf.float32, shape=[None, 5])\n",
    "        self.gt_boxes_3d = tf.placeholder(tf.float32, shape=[None, 7])\n",
    "        self.gt_boxes_corners = tf.placeholder(tf.float32, shape=[None, 25])\n",
    "        self.calib = tf.placeholder(tf.float32, shape=[None, 12])\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "        self.layers = dict({'lidar_bv_data':self.lidar_bv_data,\n",
    "                            'image_data':self.image_data,\n",
    "                            'calib' : self.calib,\n",
    "                            'im_info':self.im_info,\n",
    "                            'gt_boxes':self.gt_boxes,\n",
    "                            'gt_boxes_bv':self.gt_boxes_bv,\n",
    "                            'gt_boxes_3d': self.gt_boxes_3d,\n",
    "                            'gt_boxes_corners': self.gt_boxes_corners})\n",
    "        self.trainable = trainable\n",
    "        self.setup()\n",
    "\n",
    "        # create ops and placeholders for bbox normalization process\n",
    "        with tf.variable_scope('bbox_pred', reuse=True):\n",
    "            weights = tf.get_variable(\"weights\")\n",
    "            biases = tf.get_variable(\"biases\")\n",
    "\n",
    "            self.bbox_weights = tf.placeholder(weights.dtype, shape=weights.get_shape())\n",
    "            self.bbox_biases = tf.placeholder(biases.dtype, shape=biases.get_shape())\n",
    "\n",
    "            self.bbox_weights_assign = weights.assign(self.bbox_weights)\n",
    "            self.bbox_bias_assign = biases.assign(self.bbox_biases)\n",
    "\n",
    "    def setup(self):\n",
    "        # Lidar Bird View\n",
    "        (self.feed('lidar_bv_data')\n",
    "             .conv(3, 3, 64, 1, 1, name='conv1_1')\n",
    "             .conv(3, 3, 64, 1, 1, name='conv1_2')\n",
    "             .max_pool(2, 2, 2, 2, padding='VALID', name='pool1')\n",
    "             .conv(3, 3, 128, 1, 1, name='conv2_1')\n",
    "             .conv(3, 3, 128, 1, 1, name='conv2_2')\n",
    "             .max_pool(2, 2, 2, 2, padding='VALID', name='pool2')\n",
    "             .conv(3, 3, 256, 1, 1, name='conv3_1')\n",
    "             .conv(3, 3, 256, 1, 1, name='conv3_2')\n",
    "             .conv(3, 3, 256, 1, 1, name='conv3_3')\n",
    "             .max_pool(2, 2, 2, 2, padding='VALID', name='pool3')\n",
    "             .conv(3, 3, 512, 1, 1, name='conv4_1')\n",
    "             .conv(3, 3, 512, 1, 1, name='conv4_2')\n",
    "             .conv(3, 3, 512, 1, 1, name='conv4_3')\n",
    "             .conv(3, 3, 512, 1, 1, name='conv5_1')\n",
    "             .conv(3, 3, 512, 1, 1, name='conv5_2')\n",
    "             .conv(3, 3, 512, 1, 1, name='conv5_3'))\n",
    "        # RGB\n",
    "        (self.feed('image_data')\n",
    "              .conv(3, 3, 64, 1, 1, name='conv1_1_2')\n",
    "              .conv(3, 3, 64, 1, 1, name='conv1_2_2')\n",
    "              .max_pool(2, 2, 2, 2, padding='VALID', name='pool1_2')\n",
    "              .conv(3, 3, 128, 1, 1, name='conv2_1_2')\n",
    "              .conv(3, 3, 128, 1, 1, name='conv2_2_2')\n",
    "              .max_pool(2, 2, 2, 2, padding='VALID', name='pool2_2')\n",
    "              .conv(3, 3, 256, 1, 1, name='conv3_1_2')\n",
    "              .conv(3, 3, 256, 1, 1, name='conv3_2_2')\n",
    "              .conv(3, 3, 256, 1, 1, name='conv3_3_2')\n",
    "              .max_pool(2, 2, 2, 2, padding='VALID', name='pool3_2')\n",
    "              .conv(3, 3, 512, 1, 1, name='conv4_1_2')\n",
    "              .conv(3, 3, 512, 1, 1, name='conv4_2_2')\n",
    "              .conv(3, 3, 512, 1, 1, name='conv4_3_2')\n",
    "              .conv(3, 3, 512, 1, 1, name='conv5_1_2')\n",
    "              .conv(3, 3, 512, 1, 1, name='conv5_2_2')\n",
    "              .conv(3, 3, 512, 1, 1, name='conv5_3_2'))\n",
    "\n",
    "        #========= RPN ============\n",
    "\n",
    "        (self.feed('conv5_3')\n",
    "             # .deconv(shape=None, c_o=512, stride=2, ksize=3,  name='deconv_2x_1')\n",
    "             .conv(3,3,512,1,1,name='rpn_conv/3x3')\n",
    "             .conv(1,1,len(anchor_scales)*2*2 ,1 , 1, padding='VALID', relu = False, name='rpn_cls_score'))\n",
    "\n",
    "        (self.feed('rpn_cls_score','gt_boxes_bv', 'gt_boxes_3d', 'im_info')\n",
    "             .anchor_target_layer(_feat_stride[0], anchor_scales, name = 'rpn_data' ))\n",
    "\n",
    "        # Loss of rpn_cls & rpn_boxes\n",
    "        # anchor_num * xyzhlw\n",
    "        # offset\n",
    "        (self.feed('rpn_conv/3x3')\n",
    "             .conv(1,1,len(anchor_scales)*2*6, 1, 1, padding='VALID', relu = False, name='rpn_bbox_pred'))\n",
    "\n",
    "        #========= RoI Proposal ============\n",
    "        # Lidar Bird View\n",
    "        (self.feed('rpn_cls_score')\n",
    "             .reshape_layer(2,name = 'rpn_cls_score_reshape')\n",
    "             .softmax(name='rpn_cls_prob'))\n",
    "\n",
    "        (self.feed('rpn_cls_prob')\n",
    "             .reshape_layer(len(anchor_scales)*2*2,name = 'rpn_cls_prob_reshape'))\n",
    "\n",
    "        (self.feed('rpn_cls_prob_reshape','rpn_bbox_pred','im_info', 'calib')\n",
    "             .proposal_layer_3d(_feat_stride[0], 'TRAIN', name = 'rpn_rois'))\n",
    "\n",
    "        (self.feed('rpn_rois', 'gt_boxes_bv', 'gt_boxes_3d', 'gt_boxes_corners', 'calib')\n",
    "             .proposal_target_layer_3d(n_classes, name='roi_data_3d'))\n",
    "\n",
    "        (self.feed('roi_data_3d')\n",
    "             .proposal_transform(target='img', name='roi_data_img'))\n",
    "        (self.feed('roi_data_3d')\n",
    "             .proposal_transform(target='bv', name='roi_data_bv'))     \n",
    "\n",
    "        (self.feed('conv5_3', 'roi_data_bv')\n",
    "          .roi_pool(7, 7, 1.0/8, name='pool_5')\n",
    "          .fc(2048, name='fc6_1')\n",
    "          .dropout(self.keep_prob, name='drop6')\n",
    "          .fc(2048, name='fc7_1')\n",
    "          .dropout(self.keep_prob, name='drop7'))\n",
    "\n",
    "        # image\n",
    "        #(self.feed('deconv_2x_2', 'roi_data_img')\n",
    "        (self.feed('conv5_3_2', 'roi_data_img')\n",
    "             .roi_pool(7, 7, 1.0/8, name='pool_5_2')\n",
    "             .fc(2048, name='fc6_2')\n",
    "             .dropout(self.keep_prob, name='drop6_2')\n",
    "              .fc(2048, name='fc7_2')\n",
    "              .dropout(self.keep_prob, name='drop7_2'))\n",
    "\n",
    "        # fusion\n",
    "        (self.feed('drop7', 'drop7_2')\n",
    "             .concat(axis=1, name='concat1')\n",
    "             .dropout(self.keep_prob, name='drop7')\n",
    "             .fc(n_classes, relu=False, name='cls_score')\n",
    "             .softmax(name='cls_prob'))\n",
    "\n",
    "        (self.feed('drop7')\n",
    "             .fc(n_classes*24, relu=False, name='bbox_pred')) # (x0-x7,y0-y7,z0-z7)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use network `MV3D_train` in training\n"
     ]
    }
   ],
   "source": [
    "print 'Use network `{:s}` in training'.format(network_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = \"/workspace/MV3D_TF/data/pretrain_model/VGG_imagenet.npy\"\n",
    "max_iters = 1\n",
    "#train_net(network, imdb, roidb, output_dir, pretrained_model=pretrained_model, max_iters=max_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "def train_net(network, imdb, roidb, output_dir, pretrained_model=None, max_iters=10000):\n",
    "    \"\"\"Train a Fast R-CNN network.\"\"\"\n",
    "    roidb = filter_roidb(roidb)\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        sw = SolverWrapper(sess, saver, network, imdb, roidb, output_dir, pretrained_model=pretrained_model)\n",
    "        print 'Solving...'\n",
    "        sw.train_model(sess, max_iters)\n",
    "        print 'done solving'\n",
    "```\n",
    "## 4.2 filter_roidb(roidb) : 이미지가 없는 RoI들 제거\n",
    "\n",
    "```python\n",
    "def filter_roidb(roidb):\n",
    "    \"\"\"Remove roidb entries that have no usable RoIs.\"\"\"\n",
    "    \n",
    "  return filtered_roidb\n",
    "```\n",
    "\n",
    "## 4.3 sw.train_model() : 메인!!!\n",
    "```python\n",
    "    def train_model(self, sess, max_iters):\n",
    "        \"\"\"Network training loop.\"\"\"\n",
    "\n",
    "        data_layer = get_data_layer(self.roidb, self.imdb.num_classes)   ## 4.3.1 입력층 중요 \n",
    "\n",
    "        # RPN\n",
    "        \n",
    "        # bounding box regression L1 loss\n",
    "        \n",
    "        #  rpn_bbox_targets = tf.transpose(self.net.get_output('rpn_data')[1],[0,2,3,1])\n",
    "        rpn_bbox_targets = self.net.get_output('rpn_data')[1]\n",
    "\n",
    "        rpn_smooth_l1 = self._modified_smooth_l1(3.0, rpn_bbox_pred, rpn_bbox_targets)\n",
    "\n",
    "        # R-CNN\n",
    "        # classification loss\n",
    "        cls_score = self.net.get_output('cls_score')\n",
    "\n",
    "        # bounding box regression L1 loss\n",
    "        bbox_pred = self.net.get_output('bbox_pred')\n",
    "        bbox_targets = self.net.get_output('roi_data_3d')[3]\n",
    "\n",
    "        smooth_l1 = self._modified_smooth_l1(3.0, bbox_pred, bbox_targets)\n",
    "\n",
    "        # final loss\n",
    "        loss = cross_entropy + loss_box + rpn_cross_entropy +  rpn_loss_box\n",
    "\n",
    "        # optimizer and learning rate\n",
    "        # global_step = tf.Variable(0, trainable=False)\n",
    "        # lr = tf.train.exponential_decay(cfg.TRAIN.LEARNING_RATE, global_step,\n",
    "        #                                 cfg.TRAIN.STEPSIZE, 0.1, staircase=True)\n",
    "        #  momentum = cfg.TRAIN.MOMENTUM\n",
    "        #  train_op = tf.train.MomentumOptimizer(lr, momentum).minimize(loss, global_step=global_step)\n",
    "        lr = 0.00001\n",
    "        # train_op = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "        train_op = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "\n",
    "        # iintialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        self.net.load(self.pretrained_model, sess, self.saver, True)\n",
    "\n",
    "        for iter in range(max_iters):\n",
    "            # get one batch\n",
    "            blobs = data_layer.forward()\n",
    "\n",
    "            # Make one SGD update\n",
    "            feed_dict={self.net.image_data: blobs['image_data'],\n",
    "                       self.net.lidar_bv_data: blobs['lidar_bv_data'],\n",
    "                       self.net.im_info: blobs['im_info'],\n",
    "                       self.net.keep_prob: 0.5,\n",
    "                       self.net.gt_boxes: blobs['gt_boxes'],\n",
    "                       self.net.gt_boxes_bv: blobs['gt_boxes_bv'],\n",
    "                       self.net.gt_boxes_3d: blobs['gt_boxes_3d'],\n",
    "                       self.net.gt_boxes_corners: blobs['gt_boxes_corners'],\n",
    "                       self.net.calib: blobs['calib']}\n",
    "\n",
    "\n",
    "#########\n",
    "rpn_bbox_pred_out,rpn_loss_cls_value, rpn_loss_box_value,loss_cls_value, loss_box_value, _ \n",
    "    = sess.run([rpn_bbox_pred, rpn_cross_entropy, rpn_loss_box, cross_entropy, loss_box, train_op],feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)\n",
    "##########\n",
    "\n",
    "\n",
    "```\n",
    "### 4.3.1 get_data_layer() : 입력층 \n",
    "\n",
    "```python \n",
    "def get_data_layer(roidb, num_classes):\n",
    "    \"\"\"return a data layer.\"\"\"\n",
    "    if cfg.TRAIN.HAS_RPN:\n",
    "        if cfg.IS_MULTISCALE:\n",
    "            layer = GtDataLayer(roidb)\n",
    "        else:\n",
    "            layer = RoIDataLayer(roidb, num_classes)\n",
    "    else:\n",
    "        layer = RoIDataLayer(roidb, num_classes)\n",
    "```\n",
    "\n",
    "#### 4.3.2 RoIDataLayer\n",
    "```python\n",
    "class RoIDataLayer(object):\n",
    "    \"\"\"Fast R-CNN data layer used for training.\"\"\"\n",
    "\n",
    "    def __init__(self, roidb, num_classes):\n",
    "        \"\"\"Set the roidb to be used by this layer during training.\"\"\"\n",
    "        self._roidb = roidb\n",
    "        self._num_classes = num_classes\n",
    "        self._shuffle_roidb_inds()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2_gpu]",
   "language": "python",
   "name": "conda-env-python2_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
